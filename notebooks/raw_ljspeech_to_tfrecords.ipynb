{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "editable": true,
    "id": "ucMoYase6URl"
   },
   "source": [
    "# Load sounds with tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import random\n",
    "import os, sys\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hparams import hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "2748579840/2748572632 [==============================] - 76s 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_root_orig = tf.keras.utils.get_file(origin='https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2',\n",
    "                                         fname='LJSpeech-1.1', untar=True, cache_dir=hparams['data_dir'])\n",
    "\n",
    "data_root = pathlib.Path(data_root_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = pathlib.Path(hparams['data_dir'])\n",
    "all_sound_paths = list(data_root.glob('*/*'))\n",
    "all_sound_paths = [str(path) for path in all_sound_paths]\n",
    "\n",
    "random.seed(a=1234)\n",
    "random.shuffle(all_sound_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Pre-process wav files helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_wav_file(sound_path, hparams):\n",
    "    sound = tf.io.read_file(sound_path)   \n",
    "    return preprocess_wav_file(sound, hparams)\n",
    "\n",
    "def preprocess_wav_file(sound, hparams):\n",
    "    '''\n",
    "    Read wav file and compute mel spectrogram\n",
    "    '''\n",
    "    signal = tf.squeeze(tf.audio.decode_wav(sound).audio)\n",
    "    max_start = signal.shape[0] - hparams['segment_length']\n",
    "    start = random.randrange(0, max_start)\n",
    "    sound_tensor = signal[start:start+hparams['segment_length']]\n",
    "\n",
    "    mel = compute_mel_spectrogram(sound_tensor, hparams)\n",
    "    \n",
    "    sound_tensor = tf.cast(sound_tensor, dtype=hparams['ftype'])\n",
    "    mel = tf.cast(mel, dtype=hparams['ftype'])\n",
    "    \n",
    "    return sound_tensor, mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mel_spectrogram(sound_tensor, hparams):\n",
    "    '''\n",
    "    Compute mel spectrogram from sound tensor\n",
    "    '''\n",
    "    \n",
    "    stft = tf.signal.stft(sound_tensor,\n",
    "                          frame_length=hparams['fft_size'],\n",
    "                          frame_step=hparams['hop_size'],\n",
    "                          fft_length=hparams['fft_size'],\n",
    "                          pad_end=True)\n",
    "    \n",
    "    magnitude = tf.abs(stft)\n",
    "\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      hparams['mel_channels'], \n",
    "      magnitude.shape[-1],\n",
    "      hparams['sample_rate'], \n",
    "      hparams['fmin'],\n",
    "      hparams['fmax'])\n",
    "\n",
    "    # Mel Spectrogram\n",
    "    mel = tf.tensordot(magnitude, linear_to_mel_weight_matrix, 1)\n",
    "    mel = tf.math.log(tf.maximum(mel, 1e-5)) # log scaling with clamping\n",
    "    mel = tf.cast(mel, dtype=hparams['ftype'])\n",
    "    \n",
    "    return mel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize function and proto tf.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_example(sound_path, hparams):\n",
    "  '''\n",
    "  Creates a tf.Example message from wav, mel\n",
    "  '''\n",
    "\n",
    "  wav, mel = load_and_preprocess_wav_file(sound_path, hparams)\n",
    "\n",
    "  features = {\n",
    "      \"wav\": _bytes_feature(tf.io.serialize_tensor(wav)),\n",
    "      \"mel\": _bytes_feature(tf.io.serialize_tensor(mel))\n",
    "  }\n",
    "\n",
    "  return tf.train.Example(\n",
    "      features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write TFRecord File for validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterator to avoid writing any sample twice\n",
    "path_ds = iter(tf.data.Dataset.from_tensor_slices(all_sound_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_tfrecords_writer(path_ds, record_file, n_samples, hparams):\n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        for path, sample in zip(path_ds, range(n_samples)):\n",
    "            tf_example = sound_example(path, hparams)\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Samples\n",
    "record_file = hparams['tfrecords_dir'] + hparams['eval_file']\n",
    "sample = hparams['n_eval_samples']\n",
    "single_tfrecords_writer(path_ds, record_file, sample, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Samples\n",
    "record_file = hparams['tfrecords_dir'] + hparams['test_file']\n",
    "sample = hparams['n_test_samples']\n",
    "single_tfrecords_writer(path_ds, record_file, sample, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training Dataset in TFRecords Shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000 1084\n"
     ]
    }
   ],
   "source": [
    "sample = len(all_sound_paths) - hparams['n_eval_samples'] - hparams['n_test_samples']\n",
    "sample_per_shard = math.ceil(sample / hparams['n_shards'])\n",
    "print(sample, sample_per_shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_0_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_1_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_2_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_3_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_4_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_5_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_6_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_7_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_8_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_9_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_10_of_11.tfrecords\n",
      "Currently saving 1084 samples in : \n",
      "/home/phd/Projects/waveglow-tensorflow2/data/float32/ljs_train_11_of_11.tfrecords\n"
     ]
    }
   ],
   "source": [
    "for idx_shard in range(hparams['n_shards']):\n",
    "  print(\"Currently saving {} samples in : \".format(sample_per_shard))\n",
    "  fname = hparams['train_files'] +\\\n",
    "    '_{}_of_{}.tfrecords'.format(idx_shard, hparams['n_shards'] - 1)\n",
    "  current_path = os.path.join(hparams['tfrecords_dir'], fname)\n",
    "  print(current_path)\n",
    "  with tf.io.TFRecordWriter(current_path) as writer:        \n",
    "    for path, sample in zip(path_ds, range(sample_per_shard)):            \n",
    "      tf_example = sound_example(tf.constant(path), hparams)\n",
    "      writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2rc",
   "language": "python",
   "name": "tf2rc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
